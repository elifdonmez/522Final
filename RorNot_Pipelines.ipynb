{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from typing import Dict\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import glob\n",
    "import torch\n",
    "import wget\n",
    "import zipfile\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.models.fasttext import FastText\n",
    "\n",
    "from mittens import GloVe as Glove\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import load_model\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from setfit import SetFitModel, SetFitTrainer\n",
    "from datasets import load_dataset, logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import XLNetForSequenceClassification, RobertaForSequenceClassification\n",
    "from transformers import XLMRobertaForSequenceClassification, DistilBertForSequenceClassification\n",
    "from transformers import RobertaTokenizer, XLMRobertaTokenizer, DistilBertTokenizer, XLNetTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_report(results, folds):\n",
    "    \n",
    "    \"\"\"\n",
    "    function takes the input of predicted model results on five folds and returns\n",
    "    average of weighted and macro Precision, Recall, F-1 \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    weighted_precision = []\n",
    "    weighted_recall = []\n",
    "    weighted_f1 = []\n",
    "    \n",
    "    macro_precision = []\n",
    "    macro_recall = []\n",
    "    macro_f1 = []\n",
    "    \n",
    "    for result_df in results:                        \n",
    "        res_rows = result_df.tail(3)\n",
    "\n",
    "        precision_scores =  res_rows['precision'].tolist()\n",
    "        recall_scores =  res_rows['recall'].tolist()\n",
    "        f1_scores =  res_rows['f1-score'].tolist()\n",
    "\n",
    "        precision_macro_avg =  precision_scores[1]\n",
    "        precision_weighted_avg = precision_scores[2]\n",
    "\n",
    "        recall_macro_avg =  recall_scores[1]\n",
    "        recall_weighted_avg = recall_scores[2]\n",
    "\n",
    "        fl_accuracy = f1_scores[0]\n",
    "        f1_scores_macro_avg =  f1_scores[1]\n",
    "        f1_scores_weighted_avg = f1_scores[2]\n",
    "                \n",
    "        weighted_precision.append(precision_weighted_avg)\n",
    "        weighted_recall.append(recall_weighted_avg)\n",
    "        weighted_f1.append(f1_scores_weighted_avg)\n",
    "        \n",
    "        macro_precision.append(precision_macro_avg)\n",
    "        macro_recall.append(recall_macro_avg)\n",
    "        macro_f1.append(f1_scores_macro_avg)\n",
    "                \n",
    "    weighted_average = round(sum(weighted_precision) / folds, 2), round(sum(weighted_recall) / folds, 2), round(sum(weighted_f1) / folds, 2)\n",
    "    macro_average = round(sum(macro_precision) / folds, 2), round(sum(macro_recall) / folds, 2), round(sum(macro_f1) / folds, 2)\n",
    "            \n",
    "    return weighted_average, macro_average\n",
    "\n",
    "def get_accuracy(y_actual, y_predicted):\n",
    "    \"\"\"\n",
    "    function takes the actual and predicted labels to return\n",
    "    the accuracy per fold\n",
    "    \n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for index in zip(y_actual, y_predicted):\n",
    "        \n",
    "        if index[0] == index[1]:\n",
    "                count += 1\n",
    "    topk_acc = round(count / len(y_actual), 2)\n",
    "    return topk_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML alogrithms Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ML_model_files(model_name, model_path, pca=None):\n",
    "\n",
    "    \"\"\"\n",
    "    function load the ML models relevant files based\n",
    "    on the parameters given\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"BASACEK MI?\")\n",
    "    print(\"Model PATH:\" + model_path + '/'+ model_name + '.pickle')\n",
    "    ML_model = pickle.load(open(model_path + '/'+ model_name + '.pickle', 'rb'))\n",
    "    print(\"GURECEK MI\")\n",
    "    print(pca)\n",
    "    print(model_path + 'pca_vectorizer.pickle')\n",
    "    if pca != None:\n",
    "        pca_vectorizer = pickle.load(open(model_path + 'pca_vectorizer.pickle', 'rb'))\n",
    "    else:\n",
    "        pca_vectorizer = None\n",
    "    tfidf_vectorizer = pickle.load(open(model_path + 'tfidf_vectorizer.pickle', 'rb'))\n",
    "\n",
    "    return ML_model, pca_vectorizer, tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset for testing\n",
    "fold_parent = './data/dronology_five_folds/'\n",
    "\n",
    "sub_folders = []\n",
    "for folder in os.listdir(fold_parent):\n",
    "    if 'fold' in folder: \n",
    "        sub_folders.append(os.path.join(fold_parent, folder))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the value of 'model_name' with desired tradional ML model's name to get results for the model\n",
    "# to trigger more traditional ML models check the names in: model/ML_models. examples, DT, SVM, pLR etc. \n",
    "# put 'p' infront of the model name to couple our pre-processing pipeline\n",
    "model_name = 'LR'\n",
    "PCA = True\n",
    "map_labels = {0: 'information', 1: 'requirement'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASACEK MI?\n",
      "Model PATH:./models/ML_models/LR/fold_1//LR.pickle\n",
      "GURECEK MI\n",
      "True\n",
      "./models/ML_models/LR/fold_1/pca_vectorizer.pickle\n",
      "\n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "BASACEK MI?\n",
      "Model PATH:./models/ML_models/LR/fold_2//LR.pickle\n",
      "GURECEK MI\n",
      "True\n",
      "./models/ML_models/LR/fold_2/pca_vectorizer.pickle\n",
      "\n",
      " [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "BASACEK MI?\n",
      "Model PATH:./models/ML_models/LR/fold_3//LR.pickle\n",
      "GURECEK MI\n",
      "True\n",
      "./models/ML_models/LR/fold_3/pca_vectorizer.pickle\n",
      "\n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "BASACEK MI?\n",
      "Model PATH:./models/ML_models/LR/fold_4//LR.pickle\n",
      "GURECEK MI\n",
      "True\n",
      "./models/ML_models/LR/fold_4/pca_vectorizer.pickle\n",
      "\n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "BASACEK MI?\n",
      "Model PATH:./models/ML_models/LR/fold_5//LR.pickle\n",
      "GURECEK MI\n",
      "True\n",
      "./models/ML_models/LR/fold_5/pca_vectorizer.pickle\n",
      "\n",
      " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator PCA from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/var/folders/k1/gntrd44j2ms9z8m4589y4n440000gp/T/ipykernel_3292/737728976.py:18: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  tfidf_vectorizer = pickle.load(open(model_path + 'tfidf_vectorizer.pickle', \"rb\"))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator PCA from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/var/folders/k1/gntrd44j2ms9z8m4589y4n440000gp/T/ipykernel_3292/737728976.py:18: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  tfidf_vectorizer = pickle.load(open(model_path + 'tfidf_vectorizer.pickle', \"rb\"))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator PCA from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/var/folders/k1/gntrd44j2ms9z8m4589y4n440000gp/T/ipykernel_3292/737728976.py:18: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  tfidf_vectorizer = pickle.load(open(model_path + 'tfidf_vectorizer.pickle', \"rb\"))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator PCA from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/var/folders/k1/gntrd44j2ms9z8m4589y4n440000gp/T/ipykernel_3292/737728976.py:18: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  tfidf_vectorizer = pickle.load(open(model_path + 'tfidf_vectorizer.pickle', \"rb\"))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator PCA from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/var/folders/k1/gntrd44j2ms9z8m4589y4n440000gp/T/ipykernel_3292/737728976.py:18: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  tfidf_vectorizer = pickle.load(open(model_path + 'tfidf_vectorizer.pickle', \"rb\"))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load test data & make prediction\n",
    "\n",
    "ml_results = []\n",
    "avg_accuracy = []\n",
    "fold_count = 1\n",
    "\n",
    "for subs in sorted(sub_folders):\n",
    "    test_path = subs + '/test_' + 'fold_' + str(fold_count) + '.csv'\n",
    "\n",
    "    df_test = pd.read_csv(test_path)\n",
    "    df_test['STR.REQ'] = df_test['STR.REQ'].str.lower()\n",
    "    X_test = df_test['STR.REQ']\n",
    "    y_test = df_test['class']\n",
    "\n",
    "    model_path = './models/ML_models/' + model_name + '/fold_' + str(fold_count) + '/'\n",
    "    ML_model, pca_vectorizer, tfidf_vectorizer = load_ML_model_files(model_name, model_path, PCA)\n",
    "\n",
    "    tfidf_vecs = tfidf_vectorizer.transform(X_test)\n",
    "    normalized_tfidf = normalize(tfidf_vecs)\n",
    "\n",
    "    test_vecs = pca_vectorizer.transform(normalized_tfidf.toarray())\n",
    "    predicted_labels = ML_model.predict(test_vecs)\n",
    "\n",
    "    evaluation_results = classification_report(y_test.tolist(), predicted_labels.tolist(),\n",
    "                                               target_names=list(map_labels.values()),\n",
    "                                               output_dict=True)\n",
    "\n",
    "    avg_accuracy.append(get_accuracy(y_test.tolist(), predicted_labels.tolist()))\n",
    "\n",
    "    report_df = pd.DataFrame(evaluation_results).transpose()\n",
    "    ml_results.append(report_df)\n",
    "\n",
    "    print('\\n',predicted_labels.tolist())\n",
    "\n",
    "    fold_count += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "outputs": [],
   "source": [
    "# replace the value of 'model_name' with desired tradional ML model's name to get results for the model\n",
    "# to trigger more traditional ML models check the names in: model/ML_models. examples, DT, SVM, pLR etc.\n",
    "# put 'p' infront of the model name to couple our pre-processing pipeline\n",
    "model_name = 'NB'\n",
    "PCA = False\n",
    "map_labels = {0: 'information', 1: 'requirement'}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASACEK MI?\n",
      "Model PATH:./models/ML_models/NB/fold_1//NB.pickle\n",
      "GURECEK MI\n",
      "None\n",
      "./models/ML_models/NB/fold_1/pca_vectorizer.pickle\n",
      "SIZE PREDICTED: 18164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator GaussianNB from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/var/folders/k1/gntrd44j2ms9z8m4589y4n440000gp/T/ipykernel_3292/737728976.py:18: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  tfidf_vectorizer = pickle.load(open(model_path + 'tfidf_vectorizer.pickle', \"rb\"))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 239 features, but GaussianNB is expecting 240 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[312], line 31\u001B[0m\n\u001B[1;32m     29\u001B[0m     normalized_tfidf \u001B[38;5;241m=\u001B[39m normalize(tfidf_vecs)\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSIZE PREDICTED: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(np\u001B[38;5;241m.\u001B[39mrint(normalized_tfidf)\u001B[38;5;241m.\u001B[39mtoarray()[:, :\u001B[38;5;241m239\u001B[39m]\u001B[38;5;241m.\u001B[39msize))\n\u001B[0;32m---> 31\u001B[0m     predicted_labels \u001B[38;5;241m=\u001B[39m \u001B[43mML_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnormalized_tfidf\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtoarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m239\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     33\u001B[0m evaluation_results \u001B[38;5;241m=\u001B[39m classification_report(y_test\u001B[38;5;241m.\u001B[39mtolist(), predicted_labels\u001B[38;5;241m.\u001B[39mtolist(),\n\u001B[1;32m     34\u001B[0m                                            target_names\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlist\u001B[39m(map_labels\u001B[38;5;241m.\u001B[39mvalues()),\n\u001B[1;32m     35\u001B[0m                                            output_dict\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     37\u001B[0m avg_accuracy\u001B[38;5;241m.\u001B[39mappend(get_accuracy(y_test\u001B[38;5;241m.\u001B[39mtolist(), predicted_labels\u001B[38;5;241m.\u001B[39mtolist()))\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/naive_bayes.py:101\u001B[0m, in \u001B[0;36m_BaseNB.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m     87\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     88\u001B[0m \u001B[38;5;124;03mPerform classification on an array of test vectors X.\u001B[39;00m\n\u001B[1;32m     89\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;124;03m    Predicted target values for X.\u001B[39;00m\n\u001B[1;32m     99\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    100\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m--> 101\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_X\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    102\u001B[0m jll \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_joint_log_likelihood(X)\n\u001B[1;32m    103\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_[np\u001B[38;5;241m.\u001B[39margmax(jll, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)]\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/naive_bayes.py:269\u001B[0m, in \u001B[0;36mGaussianNB._check_X\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    267\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_X\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[1;32m    268\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Validate X, used only in predict* methods.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 269\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:626\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[1;32m    623\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m--> 626\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_n_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:415\u001B[0m, in \u001B[0;36mBaseEstimator._check_n_features\u001B[0;34m(self, X, reset)\u001B[0m\n\u001B[1;32m    412\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m    414\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_features \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_:\n\u001B[0;32m--> 415\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    416\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX has \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_features\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features, but \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    417\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis expecting \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features as input.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    418\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: X has 239 features, but GaussianNB is expecting 240 features as input."
     ]
    }
   ],
   "source": [
    "# load test data & make prediction\n",
    "\n",
    "ml_results = []\n",
    "avg_accuracy = []\n",
    "fold_count = 1\n",
    "\n",
    "for subs in sorted(sub_folders):\n",
    "    test_path = subs + '/test_' + 'fold_' + str(fold_count) + '.csv'\n",
    "\n",
    "    df_test = pd.read_csv(test_path)\n",
    "    df_test['STR.REQ'] = df_test['STR.REQ'].str.lower()\n",
    "    X_test = df_test['STR.REQ']\n",
    "    y_test = df_test['class']\n",
    "\n",
    "    model_path = './models/ML_models/' + model_name + '/fold_' + str(fold_count) + '/'\n",
    "\n",
    "    if(PCA):\n",
    "        ML_model, pca_vectorizer, tfidf_vectorizer = load_ML_model_files(model_name, model_path, PCA)\n",
    "        tfidf_vecs = tfidf_vectorizer.transform(X_test)\n",
    "        normalized_tfidf = normalize(tfidf_vecs)\n",
    "        test_vecs = pca_vectorizer.transform(normalized_tfidf.toarray())\n",
    "        print(\"AAAA#\")\n",
    "        print(test_vecs)\n",
    "        predicted_labels = ML_model.predict(test_vecs)\n",
    "\n",
    "    else:\n",
    "        ML_model, pca_vectorizer, tfidf_vectorizer = load_ML_model_files(model_name, model_path)\n",
    "        tfidf_vecs = tfidf_vectorizer.transform(X_test)\n",
    "        normalized_tfidf = normalize(tfidf_vecs)\n",
    "        print(\"SIZE PREDICTED: \" + str(np.rint(normalized_tfidf).toarray()[:, :239].size))\n",
    "        predicted_labels = ML_model.predict(np.rint(normalized_tfidf).toarray()[:, :239])\n",
    "\n",
    "    evaluation_results = classification_report(y_test.tolist(), predicted_labels.tolist(),\n",
    "                                               target_names=list(map_labels.values()),\n",
    "                                               output_dict=True)\n",
    "\n",
    "    avg_accuracy.append(get_accuracy(y_test.tolist(), predicted_labels.tolist()))\n",
    "\n",
    "    report_df = pd.DataFrame(evaluation_results).transpose()\n",
    "    ml_results.append(report_df)\n",
    "\n",
    "    print('\\n',predicted_labels.tolist())\n",
    "\n",
    "    fold_count += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "              Precision  Recall  F1_score\n5-folds                                  \nweighted_avg       0.78    0.79      0.75\nmacro_avg          0.76    0.63      0.64\naccuracy_avg       0.78    0.78      0.78",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1_score</th>\n    </tr>\n    <tr>\n      <th>5-folds</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>weighted_avg</th>\n      <td>0.78</td>\n      <td>0.79</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>macro_avg</th>\n      <td>0.76</td>\n      <td>0.63</td>\n      <td>0.64</td>\n    </tr>\n    <tr>\n      <th>accuracy_avg</th>\n      <td>0.78</td>\n      <td>0.78</td>\n      <td>0.78</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average results of ML pipeline\n",
    "\n",
    "avg_acc_score = round(np.mean(avg_accuracy), 2)\n",
    "weighted_avg, macro_avg = get_avg_report(ml_results, folds=5)\n",
    "\n",
    "avg_scores = list([weighted_avg, macro_avg, (avg_acc_score, avg_acc_score, avg_acc_score)])\n",
    "\n",
    "final_df = pd.DataFrame([x for x in avg_scores], columns=(['Precision', 'Recall', 'F1_score']),\n",
    "                      index=['weighted_avg','macro_avg', 'accuracy_avg'])\n",
    "\n",
    "final_df.rename_axis('5-folds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Family Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenizer(model_name):\n",
    "    \n",
    "    \"\"\"\n",
    "    loads and returns the relevant tokenizer for passed parameter BERT model name\n",
    "    \n",
    "    \"\"\"\n",
    "    if model_name in ('BERT_base_uncased', \n",
    "                      'pBERT_base_uncased'):\n",
    "        tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\",\n",
    "                                                  do_lower_case=True)\n",
    "                \n",
    "    elif model_name in ('BERT_base_cased',\n",
    "                        'pBERT_base_cased'):\n",
    "        tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "    \n",
    "    elif model_name in ('pXLNet_base', \n",
    "                        'XLNet_base'):\n",
    "        tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
    "    \n",
    "    elif model_name in ('SciBERT_uncased', \n",
    "                        'pSciBERT_uncased'):\n",
    "        tokenizer = BertTokenizer.from_pretrained('allenai/scibert_scivocab_uncased', \n",
    "                                                  do_lower_case=True)\n",
    "    \n",
    "    elif model_name in ('pRoBERTa_base', \n",
    "                        'RoBERTa_base'):\n",
    "        tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "    elif model_name in ('DisBERT_base_cased', \n",
    "                        'pDisBERT_base_cased'):\n",
    "        tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
    "    \n",
    "    elif model_name in ('DisBERT_base_uncased', \n",
    "                        'pDisBERT_base_uncased'):\n",
    "        tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "    else:\n",
    "        #'pXRBERT_base', 'XRBERT_base'\n",
    "        tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "    \n",
    "    return tokenizer\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_BERT_model(model_name, model_path):\n",
    "    \"\"\"\n",
    "    loads and returns the BERT model based on the model name and path parameters\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if model_name in ('BERT_base_uncased', 'pBERT_base_cased',\n",
    "                      'pBERT_base_uncased', 'BERT_base_cased',\n",
    "                      'SciBERT_uncased', 'pSciBERT_uncased'\n",
    "                     ):\n",
    "        model = BertForSequenceClassification.from_pretrained(model_path)                \n",
    "    elif model_name in ('pXLNet_base', \n",
    "                        'XLNet_base'\n",
    "                       ):\n",
    "        model = XLNetForSequenceClassification.from_pretrained(model_path)\n",
    "    \n",
    "    elif model_name in ('pRoBERTa_base', \n",
    "                        'RoBERTa_base'\n",
    "                       ):\n",
    "        model = RobertaForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "    elif model_name in ('DisBERT_base_cased', 'DisBERT_base_uncased',\n",
    "                        'pDisBERT_base_cased', 'pDisBERT_base_uncased'\n",
    "                       ):\n",
    "        model = DistilBertForSequenceClassification.from_pretrained(model_path)    \n",
    "    \n",
    "    else:\n",
    "        #'pXRBERT_base', 'XRBERT_base'\n",
    "        model = XLMRobertaForSequenceClassification.from_pretrained(model_path)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "629491560feb4320b7d20f738e46f738"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d9ba913536964972aaba9d4c379f7fa0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "decd42abc4f544d385de98d12314029c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "49f5eb0c0ec1480c9a54388ea2436a9f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# replace the value of 'model_name' with BERT model's name to get results for the model\n",
    "# to trigger more BERT models check the names in: model/BERT_family. examples, BERT_base_cased etc. \n",
    "# put 'p' infront of the model name to couple our pre-processing pipeline\n",
    "\n",
    "map_labels = {0: 'information', 1: 'requirement'}\n",
    "\n",
    "prefix = './models/DL_models/BERT_family/'\n",
    "model_name = 'BERT_base_uncased'\n",
    "\n",
    "fold_parent = './data/dronology_five_folds/'\n",
    "\n",
    "sub_folders = []\n",
    "for folder in os.listdir(fold_parent):\n",
    "    if 'fold' in folder: \n",
    "        sub_folders.append(os.path.join(fold_parent, folder))\n",
    "\n",
    "tokenizer = load_tokenizer(model_name)\n",
    "MAX_SEQ_LENGTH = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "BertTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n}"
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "fold_count = 1\n",
    "results = []\n",
    "avg_accuracy = []\n",
    "for subs in sorted(sub_folders):\n",
    "    test_path = subs + '/test_' + 'fold_' + str(fold_count) + '.csv'\n",
    "\n",
    "    df_test = pd.read_csv(test_path)\n",
    "    selected_test = df_test[['STR.REQ','class']]\n",
    "\n",
    "    test_sequences = selected_test['STR.REQ'].tolist()\n",
    "\n",
    "    test_encodings = tokenizer(test_sequences, truncation=True,\n",
    "                               padding=True,\n",
    "                               max_length=MAX_SEQ_LENGTH,\n",
    "                               return_tensors=\"pt\")\n",
    "\n",
    "    # load model\n",
    "    model_path = glob.glob(prefix + model_name + '/fold_' + str(fold_count) + '/*')[0]\n",
    "    bert_model = load_BERT_model(model_name, model_path)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = bert_model(**test_encodings).logits\n",
    "\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    evaluation_results = classification_report(selected_test['class'].tolist(),\n",
    "                                               predictions.tolist(),\n",
    "                                               target_names=list(map_labels.values()),\n",
    "                                               output_dict=True)\n",
    "\n",
    "    avg_accuracy.append(get_accuracy(selected_test['class'].tolist(),\n",
    "                                     predictions.tolist()))\n",
    "\n",
    "    report_df = pd.DataFrame(evaluation_results).transpose()\n",
    "    results.append(report_df)\n",
    "\n",
    "    print('\\n',predicted_labels.tolist())\n",
    "\n",
    "\n",
    "    fold_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "              Precision  Recall  F1_score\n5-folds                                  \nweighted_avg       0.85    0.86      0.85\nmacro_avg          0.81    0.81      0.80\naccuracy_avg       0.86    0.86      0.86",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1_score</th>\n    </tr>\n    <tr>\n      <th>5-folds</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>weighted_avg</th>\n      <td>0.85</td>\n      <td>0.86</td>\n      <td>0.85</td>\n    </tr>\n    <tr>\n      <th>macro_avg</th>\n      <td>0.81</td>\n      <td>0.81</td>\n      <td>0.80</td>\n    </tr>\n    <tr>\n      <th>accuracy_avg</th>\n      <td>0.86</td>\n      <td>0.86</td>\n      <td>0.86</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average results of BERT model\n",
    "\n",
    "avg_acc_score = round(np.mean(avg_accuracy), 2)\n",
    "weighted_avg, macro_avg = get_avg_report(results, folds=5)\n",
    "\n",
    "avg_scores = list([weighted_avg, macro_avg, (avg_acc_score, avg_acc_score, \n",
    "                                             avg_acc_score)])\n",
    "\n",
    "final_df = pd.DataFrame([x for x in avg_scores], \n",
    "                        columns=(['Precision', 'Recall', 'F1_score']),\n",
    "                        index=['weighted_avg','macro_avg', 'accuracy_avg'])\n",
    "\n",
    "final_df.rename_axis('5-folds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fewshot Family pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(path):\n",
    "    \n",
    "    \"\"\"\n",
    "    load and return the dataset in the format fine-tuned few shot sentence-BERT \n",
    "    expects\n",
    "    \n",
    "    \"\"\"\n",
    "    dataset = load_dataset(path)\n",
    "    test_dataset = dataset['test']\n",
    "    return test_dataset\n",
    "\n",
    "def _apply_column_mapping(dataset, column_mapping: Dict[str, str]):\n",
    "    \n",
    "    \"\"\"\n",
    "    apply the column mapping required for the loaded dataset\n",
    "    \n",
    "    \"\"\"\n",
    "    dataset = dataset.rename_columns(\n",
    "        {\n",
    "            **column_mapping,\n",
    "            **{col: f\"feat_{col}\" for col in dataset.column_names if col not in column_mapping},\n",
    "        }\n",
    "    )\n",
    "    dset_format = dataset.format\n",
    "    dataset = dataset.with_format(\n",
    "        type=dset_format[\"type\"],\n",
    "        columns=dataset.column_names,\n",
    "        output_all_columns=dset_format[\"output_all_columns\"],\n",
    "        **dset_format[\"format_kwargs\"],\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "def evaluate_ST(test_data, Sent_tf_model):\n",
    "    \n",
    "    \"\"\"\n",
    "    load and evaluate the Sentence-BERT model on the given test dataset\n",
    "    \n",
    "    \"\"\"\n",
    "    eval_dataset = _apply_column_mapping(test_data, \n",
    "                                         column_mapping={\"STR.REQ\": \"text\", \"class\": \"label\"})   \n",
    "    x_test = eval_dataset[\"text\"]\n",
    "    y_test = eval_dataset[\"label\"]\n",
    "    predicted_labels = Sent_tf_model.predict(x_test)\n",
    "    \n",
    "    return predicted_labels, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_labels = {0: 'information', 1: 'requirement'}\n",
    "# replace the value of 'model_name' with desired few shot model's name to get results for the model\n",
    "# to trigger morefew shot models models check the names in: model/Fewshot_family. examples, S-BERT_10% or pMiniLM_10%. \n",
    "# put 'p' infront of the model name to couple our pre-processing pipeline\n",
    "model_name = 'pS-BERT_20%'\n",
    "\n",
    "prefix = './models/DL_models/Fewshot_family/'\n",
    "fold_parent = './data/dronology_preprocess_five_folds/'\n",
    "\n",
    "sub_folders = []\n",
    "for folder in os.listdir(fold_parent):\n",
    "    if 'fold' in folder: \n",
    "        sub_folders.append(os.path.join(fold_parent, folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix: ./models/DL_models/Fewshot_family/\n",
      "model_name pS-BERT_20%\n",
      "Fold Count: 1\n",
      "Full Path: ./models/DL_models/Fewshot_family/pS-BERT_20%/fold_1/*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for dataset fold number : 1 on model : pS-BERT_20%\n",
      "\n",
      "               precision    recall  f1-score    support\n",
      "information    0.840909  0.660714  0.740000  56.000000\n",
      "requirement    0.406250  0.650000  0.500000  20.000000\n",
      "accuracy       0.657895  0.657895  0.657895   0.657895\n",
      "macro avg      0.623580  0.655357  0.620000  76.000000\n",
      "weighted avg   0.726525  0.657895  0.676842  76.000000\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "08492617e01c4e848dfa957905cf557a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2575a54cd31246ddb53798eb151db1a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72a819e58f83453eac2a8abc008f4ff5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "260be02e652b4a0e8227769a8f9b1d34"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix: ./models/DL_models/Fewshot_family/\n",
      "model_name pS-BERT_20%\n",
      "Fold Count: 2\n",
      "Full Path: ./models/DL_models/Fewshot_family/pS-BERT_20%/fold_2/*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for dataset fold number : 2 on model : pS-BERT_20%\n",
      "\n",
      "               precision    recall  f1-score    support\n",
      "information    0.857143  0.642857  0.734694  56.000000\n",
      "requirement    0.411765  0.700000  0.518519  20.000000\n",
      "accuracy       0.657895  0.657895  0.657895   0.657895\n",
      "macro avg      0.634454  0.671429  0.626606  76.000000\n",
      "weighted avg   0.739938  0.657895  0.677806  76.000000\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9646e663934b460697700951fd80b93f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "19d4ec768f434ab58a68b67e7b00cc80"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53339501efed409a9b618b47ddadaeed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2788c0727b24f0f8a8007e817cda077"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix: ./models/DL_models/Fewshot_family/\n",
      "model_name pS-BERT_20%\n",
      "Fold Count: 3\n",
      "Full Path: ./models/DL_models/Fewshot_family/pS-BERT_20%/fold_3/*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for dataset fold number : 3 on model : pS-BERT_20%\n",
      "\n",
      "               precision    recall  f1-score    support\n",
      "information    0.885714  0.563636  0.688889  55.000000\n",
      "requirement    0.400000  0.800000  0.533333  20.000000\n",
      "accuracy       0.626667  0.626667  0.626667   0.626667\n",
      "macro avg      0.642857  0.681818  0.611111  75.000000\n",
      "weighted avg   0.756190  0.626667  0.647407  75.000000\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "463d66158ec542e4899e641b729bde3d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b5a6a4836c4b47f79a63cb8bcdc0e5b4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af53c25e7e724d68b5a85bafa2dbd2c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79bcb4e1635548f2834889f4e4f586ff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix: ./models/DL_models/Fewshot_family/\n",
      "model_name pS-BERT_20%\n",
      "Fold Count: 4\n",
      "Full Path: ./models/DL_models/Fewshot_family/pS-BERT_20%/fold_4/*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for dataset fold number : 4 on model : pS-BERT_20%\n",
      "\n",
      "               precision    recall  f1-score  support\n",
      "information    0.897436  0.636364  0.744681    55.00\n",
      "requirement    0.444444  0.800000  0.571429    20.00\n",
      "accuracy       0.680000  0.680000  0.680000     0.68\n",
      "macro avg      0.670940  0.718182  0.658055    75.00\n",
      "weighted avg   0.776638  0.680000  0.698480    75.00\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3f48dfda97d461b95646cacf19953ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be083b15ea2842eaadfd0f28d9023233"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c5d723c675f240a5a50265dbfe788d2f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9cce944f3f064bccbea8175877d5ac42"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix: ./models/DL_models/Fewshot_family/\n",
      "model_name pS-BERT_20%\n",
      "Fold Count: 5\n",
      "Full Path: ./models/DL_models/Fewshot_family/pS-BERT_20%/fold_5/*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for dataset fold number : 5 on model : pS-BERT_20%\n",
      "\n",
      "               precision    recall  f1-score    support\n",
      "information    0.804348  0.660714  0.725490  56.000000\n",
      "requirement    0.344828  0.526316  0.416667  19.000000\n",
      "accuracy       0.626667  0.626667  0.626667   0.626667\n",
      "macro avg      0.574588  0.593515  0.571078  75.000000\n",
      "weighted avg   0.687936  0.626667  0.647255  75.000000\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "fold_count = 1\n",
    "st_results = []\n",
    "avg_accuracy = []\n",
    "\n",
    "for subs in sorted(sub_folders):\n",
    "    test_dataset = get_dataset(subs)\n",
    "    print(\"Prefix: \" + prefix)\n",
    "    print(\"model_name \"+ model_name )\n",
    "    print(\"Fold Count: \" + str(fold_count))\n",
    "    print(\"Full Path: \" + prefix + model_name + '/fold_' + str(fold_count) + '/*')\n",
    "    \n",
    "    model_path = prefix + model_name + '/fold_' + str(fold_count)\n",
    "    ST_model = SetFitModel.from_pretrained(model_path)\n",
    "    \n",
    "    predicted_labels, y_test = evaluate_ST(test_dataset, ST_model)\n",
    "    \n",
    "    evaluation_results = classification_report(y_test, predicted_labels.tolist(), \n",
    "                                               target_names=list(map_labels.values()), \n",
    "                                               output_dict=True)\n",
    "    \n",
    "    avg_accuracy.append(get_accuracy(y_test, \n",
    "                                     predicted_labels.tolist()))\n",
    "\n",
    "    report_df = pd.DataFrame(evaluation_results).transpose()\n",
    "    st_results.append(report_df)\n",
    "    \n",
    "    print('\\nResults for dataset fold number :',fold_count, 'on model :', model_name)\n",
    "    print('\\n',report_df)\n",
    "    print('--------------------------------------')\n",
    "\n",
    "    fold_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "              Precision  Recall  F1_score\n5-folds                                  \nweighted_avg       0.74    0.65      0.67\nmacro_avg          0.63    0.66      0.62\naccuracy_avg       0.65    0.65      0.65",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1_score</th>\n    </tr>\n    <tr>\n      <th>5-folds</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>weighted_avg</th>\n      <td>0.74</td>\n      <td>0.65</td>\n      <td>0.67</td>\n    </tr>\n    <tr>\n      <th>macro_avg</th>\n      <td>0.63</td>\n      <td>0.66</td>\n      <td>0.62</td>\n    </tr>\n    <tr>\n      <th>accuracy_avg</th>\n      <td>0.65</td>\n      <td>0.65</td>\n      <td>0.65</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_acc_score = round(np.mean(avg_accuracy), 2)\n",
    "weighted_avg, macro_avg = get_avg_report(st_results, folds=5)\n",
    "\n",
    "avg_scores = list([weighted_avg, macro_avg, (avg_acc_score, avg_acc_score, \n",
    "                                             avg_acc_score)])\n",
    "\n",
    "final_df = pd.DataFrame([x for x in avg_scores], \n",
    "                        columns=(['Precision', 'Recall', 'F1_score']),\n",
    "                        index=['weighted_avg','macro_avg', 'accuracy_avg'])\n",
    "\n",
    "final_df.rename_axis('5-folds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_model(model_name, prefix, model_path):\n",
    "    \n",
    "    embeddings_model = None\n",
    "    if model_name in ('LSTM_FT_pre-train', 'pLSTM_FT_pre-train'):\n",
    "        \n",
    "        # Load FastText pre trained embeddings\n",
    "        if not 'wiki-news-300d-1M-subword.vec' in os.listdir(prefix):\n",
    "            \n",
    "            print('Downloading FastText pretrained model for the first time...')\n",
    "            url = 'https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M-subword.vec.zip'\n",
    "            \n",
    "            wget.download(url, out=prefix)\n",
    "            with zipfile.ZipFile(prefix + 'wiki-news-300d-1M-subword.vec.zip', 'r') as zip_ref:\n",
    "                zip_ref.extractall(prefix)\n",
    "        \n",
    "        embeddings_model = KeyedVectors.load_word2vec_format(prefix + \n",
    "                                                          'wiki-news-300d-1M-subword.vec')\n",
    "        print('\\nFastText pretrained Model loaded...')        \n",
    "\n",
    "    elif model_name in ('LSTM_GLV_pre-train', 'pLSTM_GLV_pre-train'):\n",
    "        \n",
    "        # load pre trained Glove embeddings model\n",
    "        if not 'glove.6B.100d.txt' in os.listdir(prefix):\n",
    "            url = 'https://nlp.stanford.edu/data/glove.6B.zip'\n",
    "            wget.download(url, out=prefix)\n",
    "            \n",
    "            with zipfile.ZipFile(prefix + 'glove.6B.zip', 'r') as zip_ref:\n",
    "                zip_ref.extractall(prefix)\n",
    "            \n",
    "        embeddings_model = {}\n",
    "        with open(prefix + 'glove.6B.100d.txt','r') as f:\n",
    "            for line in f:\n",
    "                \n",
    "                split_line = line.split()\n",
    "                word = split_line[0]\n",
    "                embedding = np.array(split_line[1:], dtype=np.float64)\n",
    "                embeddings_model[word] = embedding\n",
    "        \n",
    "        print('\\nPretrained Glove Model loaded...')        \n",
    "                \n",
    "    elif model_name in ('LSTM_GLV_custom', 'pLSTM_GLV_custom'):\n",
    "        \n",
    "        # load custom glove embeddings model\n",
    "        embeddings_model = Glove.load(model_path + '/glove_custom_100d.model')\n",
    "        print('\\nGlove custom pretrained Model loaded...')        \n",
    "      \n",
    "    elif model_name in ('LSTM_FT_custom', 'pLSTM_FT_custom'):\n",
    "        \n",
    "        # load custom FastText embeddings model\n",
    "        embeddings_model = KeyedVectors.load(model_path + '/fast_text.model')\n",
    "        print('\\nFastText custom Model loaded...')        \n",
    "    \n",
    "    return embeddings_model          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_to_index(string_data, wv, model_name):\n",
    "    \n",
    "    index_data = []\n",
    "    for word in string_data:\n",
    "        if word in wv:\n",
    "            try:\n",
    "                if 'GLV_custom' in model_name:\n",
    "                    index_data.append(wv[word])\n",
    "\n",
    "                else:\n",
    "                    index_data.append(wv.vocab[word].index)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    return index_data\n",
    "\n",
    "def convert_data(train_sentences, test_sentences, modelf, model_name):\n",
    "    \n",
    "    train_data = []\n",
    "    i = 0\n",
    "    if 'GLV_custom' in model_name:\n",
    "        word_vectors = modelf.dictionary\n",
    "    else:\n",
    "        word_vectors = modelf.wv\n",
    "    \n",
    "    while i<len(train_sentences):\n",
    "        for seq in train_sentences[i]:\n",
    "            train_data.append(convert_data_to_index(train_sentences[i], word_vectors, \n",
    "                                                    model_name))\n",
    "            break\n",
    "\n",
    "        i+=1\n",
    "    \n",
    "    test_data = []\n",
    "    i = 0\n",
    "    while i<len(test_sentences):\n",
    "        for seq in test_sentences[i]:\n",
    "            test_data.append(convert_data_to_index(test_sentences[i], word_vectors, \n",
    "                                                   model_name))\n",
    "            break\n",
    "\n",
    "        i+=1\n",
    "    return train_data, test_data\n",
    "\n",
    "def pad_sequences(train_data, test_data):\n",
    "    \n",
    "    max_length_f = max([len(seq) for seq in train_data])   \n",
    "    test_padded = sequence.pad_sequences(test_data, maxlen=max_length_f, padding='pre')\n",
    "    return test_padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset for testing\n",
    "fold_parent = './data/dronology_preprocess_five_folds/'\n",
    "#fold_parent = '../dataset/dronology_basic_data/'\n",
    "\n",
    "\n",
    "sub_folders = []\n",
    "for folder in os.listdir(fold_parent):\n",
    "    if 'fold' in folder: \n",
    "        sub_folders.append(os.path.join(fold_parent, folder))\n",
    "        \n",
    "\n",
    "map_labels = {0: 'information', 1: 'requirement'}\n",
    "prefix = './models/DL_models/LSTM_family/'\n",
    "# replace the value of 'model_name' with desired LSTM model's name to get results for the model\n",
    "# to trigger more LSTM models check the names in: model/LSTM_family. examples, LSTM_FT_custom. \n",
    "# put 'p' infront of the model name to couple our pre-processing pipeline\n",
    "model_name = 'pLSTM_FT_custom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/DL_models/LSTM_family/pLSTM_FT_custom/fold_1/fast_text.model'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 21\u001B[0m\n\u001B[1;32m     17\u001B[0m test_sentences \u001B[38;5;241m=\u001B[39m test_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSTR.REQ\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28mstr\u001B[39m\u001B[38;5;241m.\u001B[39msplit)\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m     19\u001B[0m actual \u001B[38;5;241m=\u001B[39m test_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclass\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[0;32m---> 21\u001B[0m embeddings_model \u001B[38;5;241m=\u001B[39m \u001B[43mget_embeddings_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprefix\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mp\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m model_name\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;241m0\u001B[39m]:\n\u001B[1;32m     24\u001B[0m     lstm_model \u001B[38;5;241m=\u001B[39m load_model(model_path \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/pLSTM.h5\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[0;32mIn[18], line 50\u001B[0m, in \u001B[0;36mget_embeddings_model\u001B[0;34m(model_name, prefix, model_path)\u001B[0m\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mGlove custom pretrained Model loaded...\u001B[39m\u001B[38;5;124m'\u001B[39m)        \n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m model_name \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLSTM_FT_custom\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpLSTM_FT_custom\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m     48\u001B[0m     \n\u001B[1;32m     49\u001B[0m     \u001B[38;5;66;03m# load custom FastText embeddings model\u001B[39;00m\n\u001B[0;32m---> 50\u001B[0m     embeddings_model \u001B[38;5;241m=\u001B[39m \u001B[43mKeyedVectors\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/fast_text.model\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mFastText custom Model loaded...\u001B[39m\u001B[38;5;124m'\u001B[39m)        \n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m embeddings_model\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/gensim/utils.py:486\u001B[0m, in \u001B[0;36mSaveLoad.load\u001B[0;34m(cls, fname, mmap)\u001B[0m\n\u001B[1;32m    482\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloading \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m object from \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, fname)\n\u001B[1;32m    484\u001B[0m compress, subname \u001B[38;5;241m=\u001B[39m SaveLoad\u001B[38;5;241m.\u001B[39m_adapt_by_suffix(fname)\n\u001B[0;32m--> 486\u001B[0m obj \u001B[38;5;241m=\u001B[39m \u001B[43munpickle\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    487\u001B[0m obj\u001B[38;5;241m.\u001B[39m_load_specials(fname, mmap, compress, subname)\n\u001B[1;32m    488\u001B[0m obj\u001B[38;5;241m.\u001B[39madd_lifecycle_event(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloaded\u001B[39m\u001B[38;5;124m\"\u001B[39m, fname\u001B[38;5;241m=\u001B[39mfname)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/gensim/utils.py:1460\u001B[0m, in \u001B[0;36munpickle\u001B[0;34m(fname)\u001B[0m\n\u001B[1;32m   1446\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21munpickle\u001B[39m(fname):\n\u001B[1;32m   1447\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Load object from `fname`, using smart_open so that `fname` can be on S3, HDFS, compressed etc.\u001B[39;00m\n\u001B[1;32m   1448\u001B[0m \n\u001B[1;32m   1449\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1458\u001B[0m \n\u001B[1;32m   1459\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1460\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m   1461\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _pickle\u001B[38;5;241m.\u001B[39mload(f, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlatin1\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/smart_open/smart_open_lib.py:177\u001B[0m, in \u001B[0;36mopen\u001B[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, compression, transport_params)\u001B[0m\n\u001B[1;32m    174\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m transport_params \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    175\u001B[0m     transport_params \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m--> 177\u001B[0m fobj \u001B[38;5;241m=\u001B[39m \u001B[43m_shortcut_open\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m    \u001B[49m\u001B[43muri\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbuffering\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbuffering\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    184\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnewline\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    185\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fobj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    187\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fobj\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/smart_open/smart_open_lib.py:363\u001B[0m, in \u001B[0;36m_shortcut_open\u001B[0;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001B[0m\n\u001B[1;32m    360\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m    361\u001B[0m     open_kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124merrors\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m errors\n\u001B[0;32m--> 363\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_builtin_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocal_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffering\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbuffering\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mopen_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: './models/DL_models/LSTM_family/pLSTM_FT_custom/fold_1/fast_text.model'"
     ]
    }
   ],
   "source": [
    "fold_count = 1\n",
    "results = []\n",
    "avg_accuracy = []\n",
    "\n",
    "for subs in sorted(sub_folders):\n",
    "    train_path = subs + '/train_' + 'fold_' + str(fold_count) + '.csv'\n",
    "    test_path = subs + '/test_' + 'fold_' + str(fold_count) + '.csv'\n",
    "    \n",
    "    test_df=pd.read_csv(test_path)\n",
    "    train_df=pd.read_csv(train_path)\n",
    "    \n",
    "    model_path = prefix + model_name + '/fold_' + str(fold_count)\n",
    "    \n",
    "    test_df['STR.REQ'] =  test_df['STR.REQ'].str.lower()\n",
    "    train_df['STR.REQ'] =  train_df['STR.REQ'].str.lower()\n",
    "    train_sentences = train_df['STR.REQ'].apply(str.split).values.tolist()\n",
    "    test_sentences = test_df['STR.REQ'].apply(str.split).values.tolist()\n",
    "\n",
    "    actual = test_df['class'].tolist()\n",
    "    \n",
    "    embeddings_model = get_embeddings_model(model_name, prefix, model_path)\n",
    "\n",
    "    if 'p' in model_name.split('_')[0]:\n",
    "        lstm_model = load_model(model_path + '/pLSTM.h5')\n",
    "    else:\n",
    "        lstm_model = load_model(model_path + '/LSTM.h5')\n",
    "    \n",
    "    train_data, test_data = convert_data(train_sentences, test_sentences, \n",
    "                                         embeddings_model, model_name)\n",
    "    test_padded = pad_sequences(train_data, test_data)\n",
    "    \n",
    "    test_padded = np.array(test_padded)              \n",
    "    \n",
    "    predictions = lstm_model.predict(test_padded)\n",
    "    sorted_predictions = (-predictions).argsort()\n",
    "    top_label_int = sorted_predictions[:, :1].flatten().tolist()\n",
    "    \n",
    "    evaluation_results = metrics.classification_report(actual, top_label_int, \n",
    "                                                       target_names=list(map_labels.values()),\n",
    "                                                       output_dict=True)\n",
    "    report_df = pd.DataFrame(evaluation_results).transpose()\n",
    "    results.append(report_df)\n",
    "    print('\\nResults for dataset fold number :',fold_count, 'on model :', model_name)\n",
    "    print('\\n',report_df)\n",
    "    print('--------------------------------------')\n",
    "    \n",
    "    avg_accuracy.append(get_accuracy(actual, top_label_int))\n",
    "    fold_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-folds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weighted_avg</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro_avg</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_avg</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Precision  Recall  F1_score\n",
       "5-folds                                  \n",
       "weighted_avg       0.76    0.77      0.75\n",
       "macro_avg          0.71    0.66      0.67\n",
       "accuracy_avg       0.77    0.77      0.77"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "avg_acc_score = round(np.mean(avg_accuracy), 2)\n",
    "weighted_avg, macro_avg = get_avg_report(results, folds=5)\n",
    "\n",
    "avg_scores = list([weighted_avg, macro_avg, (avg_acc_score, avg_acc_score, \n",
    "                                             avg_acc_score)])\n",
    "\n",
    "final_df = pd.DataFrame([x for x in avg_scores], \n",
    "                        columns=(['Precision', 'Recall', 'F1_score']),\n",
    "                        index=['weighted_avg','macro_avg', 'accuracy_avg'])\n",
    "\n",
    "final_df.rename_axis('5-folds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_label(ranges):\n",
    "    \"\"\"\n",
    "    returns the random label from the defined ranges of the labels\n",
    "    \"\"\"\n",
    "    temp=random.randint(1, ranges[-1][-1])\n",
    "    \n",
    "    for r in ranges:\n",
    "        if(temp>r[1] and temp<=r[-1]):\n",
    "            return r[0]\n",
    "    return None\n",
    "\n",
    "def get_ranges(df):\n",
    "    \"\"\"\n",
    "    predicts the random labels on the given test dataset\n",
    "    \n",
    "    \"\"\"\n",
    "    csum = 0\n",
    "    ranges = []\n",
    "    total_tr = len(df)\n",
    "\n",
    "    for k, v in df['class'].value_counts().to_dict().items():\n",
    "\n",
    "        csum_old = csum\n",
    "        csum += round((v/total_tr) * 100,0)\n",
    "        #print (k,\"from\", csum_old, \"to\",csum)\n",
    "        ranges.append([k, csum_old, csum])\n",
    "    \n",
    "    r_out = []\n",
    "    for row in test_df.iterrows():\n",
    "        r3labels = []\n",
    "\n",
    "        while len(r3labels)!=1:\n",
    "            rl = get_random_label(ranges)\n",
    "            if not rl in r3labels:\n",
    "                r3labels.append(rl)\n",
    "\n",
    "        r_out.append([row[1]['issueid'], row[1]['class'], r3labels])\n",
    "\n",
    "    return ranges, r_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "fold_parent = './data/dronology_five_folds/'\n",
    "\n",
    "sub_folders = []\n",
    "for folder in os.listdir(fold_parent):\n",
    "    if 'fold' in folder: \n",
    "        sub_folders.append(os.path.join(fold_parent, folder)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for fold number : 1\n",
      "\n",
      "               precision    recall  f1-score    support\n",
      "information    0.736842  0.750000  0.743363  56.000000\n",
      "requirement    0.263158  0.250000  0.256410  20.000000\n",
      "accuracy       0.618421  0.618421  0.618421   0.618421\n",
      "macro avg      0.500000  0.500000  0.499887  76.000000\n",
      "weighted avg   0.612188  0.618421  0.615217  76.000000\n",
      "--------------------------------------\n",
      "\n",
      "Results for fold number : 2\n",
      "\n",
      "               precision    recall  f1-score    support\n",
      "information    0.754386  0.767857  0.761062  56.000000\n",
      "requirement    0.315789  0.300000  0.307692  20.000000\n",
      "accuracy       0.644737  0.644737  0.644737   0.644737\n",
      "macro avg      0.535088  0.533929  0.534377  76.000000\n",
      "weighted avg   0.638966  0.644737  0.641754  76.000000\n",
      "--------------------------------------\n",
      "\n",
      "Results for fold number : 3\n",
      "\n",
      "               precision    recall  f1-score    support\n",
      "information    0.730769  0.690909  0.710280  55.000000\n",
      "requirement    0.260870  0.300000  0.279070  20.000000\n",
      "accuracy       0.586667  0.586667  0.586667   0.586667\n",
      "macro avg      0.495819  0.495455  0.494675  75.000000\n",
      "weighted avg   0.605463  0.586667  0.595291  75.000000\n",
      "--------------------------------------\n",
      "\n",
      "Results for fold number : 4\n",
      "\n",
      "               precision    recall  f1-score  support\n",
      "information    0.729167  0.636364  0.679612    55.00\n",
      "requirement    0.259259  0.350000  0.297872    20.00\n",
      "accuracy       0.560000  0.560000  0.560000     0.56\n",
      "macro avg      0.494213  0.493182  0.488742    75.00\n",
      "weighted avg   0.603858  0.560000  0.577815    75.00\n",
      "--------------------------------------\n",
      "\n",
      "Results for fold number : 5\n",
      "\n",
      "               precision    recall  f1-score    support\n",
      "information    0.750000  0.803571  0.775862  56.000000\n",
      "requirement    0.266667  0.210526  0.235294  19.000000\n",
      "accuracy       0.653333  0.653333  0.653333   0.653333\n",
      "macro avg      0.508333  0.507049  0.505578  75.000000\n",
      "weighted avg   0.627556  0.653333  0.638918  75.000000\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "fold_count = 1\n",
    "for subs in sorted(sub_folders):\n",
    "    \n",
    "    test_path = subs + '/test_' + 'fold_' + str(fold_count) + '.csv'\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    ranges, r_out = get_ranges(test_df)\n",
    "    \n",
    "    random_out = pd.DataFrame()\n",
    "    random_out['issueid'] = [i[0] for i in r_out]\n",
    "    random_out['class'] = [i[1] for i in r_out]\n",
    "    random_out['top_label'] = [i[2][0] for i in r_out]\n",
    "    evaluation_results = classification_report(random_out['class'], random_out['top_label'], \n",
    "                                               target_names=list(map_labels.values()), \n",
    "                                               output_dict=True)\n",
    "    \n",
    "    report_df = pd.DataFrame(evaluation_results).transpose()\n",
    "    print('\\nResults for fold number :',fold_count)\n",
    "    print('\\n',report_df)\n",
    "    print('--------------------------------------')\n",
    "    \n",
    "    fold_count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
